{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1033dac0-a1b2-4f1e-bf6a-f1b8dde11126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Diaraye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Diaraye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Diaraye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Diaraye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "def convert_tag(tag):\n",
    "    \"\"\"Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets\"\"\"\n",
    "    \n",
    "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}#,'I': 'r','D':'n'\n",
    "#     tag_dict = {'NN': 'n', 'J': 'a', 'R': 'r', 'VBP': 'v'}\n",
    "    try:\n",
    "        return tag_dict[tag[1][0]]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def doc_to_synsets(doc):\n",
    "    \"\"\"\n",
    "    Returns a list of synsets in document.\n",
    "\n",
    "    Tokenizes and tags the words in the document doc.\n",
    "    Then finds the first synset for each word/tag combination.\n",
    "    If a synset is not found for that combination it is skipped.\n",
    "\n",
    "    Args:\n",
    "        doc: string to be converted\n",
    "\n",
    "    Returns:\n",
    "        list of synsets\n",
    "\n",
    "    Example:\n",
    "        doc_to_synsets('Fish are nvqjp friends.')\n",
    "        Out: [Synset('fish.n.01'), Synset('be.v.01'), Synset('friend.n.01')]\n",
    "    \"\"\"\n",
    "    text=word_tokenize(doc)\n",
    "    tags=pos_tag(text)\n",
    "    nw_tags=[convert_tag(i) for i in tags]\n",
    "    df=pd.DataFrame([tags,nw_tags]).transpose()\n",
    "    df.columns=['Tags','Nw_tags']\n",
    "#     df=df[df['Nw_tags']!=None]\n",
    "    # df=df.dropna()\n",
    "    # df=df.reset_index()\n",
    "    syns=[]\n",
    "    for i in range(0,df.shape[0]):\n",
    "        try:\n",
    "            syns.append(wn.synsets(df.Tags[i][0],pos=df.Nw_tags[i])[0])\n",
    "        except:\n",
    "            continue\n",
    "    # sy=[i for j,i in syns if i>0]\n",
    "    return syns\n",
    "\n",
    "\n",
    "def similarity_score(s1, s2):\n",
    "    \"\"\"\n",
    "    Calculate the normalized similarity score of s1 onto s2\n",
    "\n",
    "    For each synset in s1, finds the synset in s2 with the largest similarity value.\n",
    "    Sum of all of the largest similarity values and normalize this value by dividing it by the\n",
    "    number of largest similarity values found.\n",
    "\n",
    "    Args:\n",
    "        s1, s2: list of synsets from doc_to_synsets\n",
    "\n",
    "    Returns:\n",
    "        normalized similarity score of s1 onto s2\n",
    "\n",
    "    Example:\n",
    "        synsets1 = doc_to_synsets('I like cats')\n",
    "        synsets2 = doc_to_synsets('I like dogs')\n",
    "        similarity_score(synsets1, synsets2)\n",
    "        Out: 0.73333333333333339\n",
    "    \"\"\"\n",
    "    y=[]\n",
    "    for i in s1:\n",
    "          y.append(max([i.path_similarity(j) for j in s2 if type(i.path_similarity(j))==float and i.path_similarity(j)!=[]]))\n",
    "        \n",
    "    return sum(y)/len(y)\n",
    "###########################333333\n",
    "#     y=[]\n",
    "#     for i in s1:\n",
    "#         y.append(max([i.path_similarity(j) for j in s2 if type(i.path_similarity(j))==float]))\n",
    "    \n",
    "#     return sum(y)/len(y)\n",
    "\n",
    "def document_path_similarity(doc1, doc2):\n",
    "    \"\"\"Finds the symmetrical similarity between doc1 and doc2\"\"\"\n",
    "\n",
    "    synsets1 = doc_to_synsets(doc1)\n",
    "    synsets2 = doc_to_synsets(doc2)\n",
    "\n",
    "    return (similarity_score(synsets1, synsets2) + similarity_score(synsets2, synsets1)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "edbb4ca8-dde1-43d4-8480-138720cc20a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    Calculate the normalized similarity score of s1 onto s2\\n\\n    For each synset in s1, finds the synset in s2 with the largest similarity value.\\n    Sum of all of the largest similarity values and normalize this value by dividing it by the\\n    number of largest similarity values found.\\n\\n    Args:\\n        s1, s2: list of synsets from doc_to_synsets\\n\\n    Returns:\\n        normalized similarity score of s1 onto s2\\n\\n    Example:\\n        synsets1 = doc_to_synsets('I like cats')\\n        synsets2 = doc_to_synsets('I like dogs')\\n        similarity_score(synsets1, synsets2)\\n        Out: 0.73333333333333339\\n    \""
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Calculate the normalized similarity score of s1 onto s2\n",
    "\n",
    "    For each synset in s1, finds the synset in s2 with the largest similarity value.\n",
    "    Sum of all of the largest similarity values and normalize this value by dividing it by the\n",
    "    number of largest similarity values found.\n",
    "\n",
    "    Args:\n",
    "        s1, s2: list of synsets from doc_to_synsets\n",
    "\n",
    "    Returns:\n",
    "        normalized similarity score of s1 onto s2\n",
    "\n",
    "    Example:\n",
    "        synsets1 = doc_to_synsets('I like cats')\n",
    "        synsets2 = doc_to_synsets('I like dogs')\n",
    "        similarity_score(synsets1, synsets2)\n",
    "        Out: 0.73333333333333339\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "21c150d9-f866-4740-af12-0361061a01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_synsets(doc):\n",
    "    text=word_tokenize(doc)\n",
    "    tags=pos_tag(text)\n",
    "    nw_tags=[convert_tag(i) for i in tags]\n",
    "    # df=pd.DataFrame([tags,nw_tags]).transpose()\n",
    "    # df.columns=['Tags','Nw_tags']\n",
    "#     df=df[df['Nw_tags']!=None]\n",
    "    # df=df.dropna()\n",
    "    # df=df.reset_index()\n",
    "    syns=[]\n",
    "    for i in range(0,len(tags)):\n",
    "        try:\n",
    "            syns.append(wn.synsets(tags[i][0],pos=nw_tags[i])[0])\n",
    "        except:\n",
    "            continue\n",
    "    # syns.append(wn.synsets(tags[i][0],pos=nw_tags[i])[0])\n",
    "    return syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2dfc54db-0b70-4537-8bdf-10ff746486f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('I', 'PRP'), ('like', 'VBP'), ('cats', 'NNS')],\n",
       " [None, 'v', 'n'],\n",
       " [Synset('iodine.n.01'),\n",
       "  Synset('one.n.01'),\n",
       "  Synset('i.n.03'),\n",
       "  Synset('one.s.01')])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=word_tokenize('I like cats')\n",
    "tags1=pos_tag(text1)\n",
    "nw_tags1=[convert_tag(i) for i in tags1]\n",
    "tags1,nw_tags1,wn.synsets(tags1[0][0],pos=nw_tags1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d03caf67-7975-4060-8fb2-1acd34913b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.25, 1.0, 0.2]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similarity_score(s1,s2):\n",
    "    def sim(h,ser):\n",
    "        y=[h.path_similarity(i) for i in ser]\n",
    "        return y\n",
    "    z=[]\n",
    "    for j in s1:\n",
    "        z.append(max(sim(j,s2)))\n",
    "    \n",
    "    return z\n",
    "similarity_score(sy1,sy2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b73257a6-68db-4c9e-838c-a5bf37321e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 'a'), (1, 'b'), (1, 'c'), (1, 'd')],\n",
       " [(2, 'a'), (2, 'b'), (2, 'c'), (2, 'd')],\n",
       " [(3, 'a'), (3, 'b'), (3, 'c'), (3, 'd')]]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cortup(x,y):\n",
    "    def cort(xi,ser):\n",
    "        y=[(xi,i) for i in ser]\n",
    "        return y\n",
    "    z=[]\n",
    "    for j in x:\n",
    "        z.append(cort(j,y))\n",
    "    return z\n",
    "a=[1,2,3]\n",
    "b=['a','b','c','d']\n",
    "cortup(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2f9ef2dd-ea2a-4c65-a285-eb187c8c70fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.3333333333333333,\n",
       "  0.14285714285714285,\n",
       "  0.25,\n",
       "  0.14285714285714285,\n",
       "  0.1111111111111111,\n",
       "  1.0,\n",
       "  0.3333333333333333],\n",
       " [0.1, 0.1, 0.09090909090909091, 0.1, 0.25, 0.1, 0.1],\n",
       " [0.14285714285714285,\n",
       "  1.0,\n",
       "  0.125,\n",
       "  0.14285714285714285,\n",
       "  0.1111111111111111,\n",
       "  0.14285714285714285,\n",
       "  0.14285714285714285])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim(xi,ser):\n",
    "        y=[xi.path_similarity(i) for i in ser]\n",
    "        return y\n",
    "doc1 = 'This is a function to test document_path_similarity.'\n",
    "doc2 = 'Use this function to see if your code in doc_to_synsets \\\n",
    "and similarity_score is correct!'\n",
    "sy1=doc_to_synsets(doc1)\n",
    "sy2=doc_to_synsets(doc2)\n",
    "sim(sy1[0],sy2),sim(sy1[1],sy2),sim(sy1[2],sy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "18ccb945-3f62-46a9-b32e-f51a6f6f135e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.2]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zu='I like \\\n",
    "cats'\n",
    "# \n",
    "synsets1 = doc_to_synsets(zu)\n",
    "synsets2 = doc_to_synsets('I like dogs')\n",
    "similarity_score(synsets1, synsets2)\n",
    "# Out: 0.73333333333333339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ea7f64b2-b4c3-4d91-bd2c-21e543bf62f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [269]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     doc2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse this function to see if your code in doc_to_synsets \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    and similarity_score is correct!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m document_path_similarity(doc1, doc2)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtest_document_path_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [269]\u001b[0m, in \u001b[0;36mtest_document_path_similarity\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m doc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis is a function to test document_path_similarity.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m doc2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse this function to see if your code in doc_to_synsets \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mand similarity_score is correct!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdocument_path_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [249]\u001b[0m, in \u001b[0;36mdocument_path_similarity\u001b[1;34m(doc1, doc2)\u001b[0m\n\u001b[0;32m     96\u001b[0m synsets1 \u001b[38;5;241m=\u001b[39m doc_to_synsets(doc1)\n\u001b[0;32m     97\u001b[0m synsets2 \u001b[38;5;241m=\u001b[39m doc_to_synsets(doc2)\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43msimilarity_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43msynsets1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynsets2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msimilarity_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43msynsets2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynsets1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "def test_document_path_similarity():\n",
    "    doc1 = 'This is a function to test document_path_similarity.'\n",
    "    doc2 = 'Use this function to see if your code in doc_to_synsets \\\n",
    "    and similarity_score is correct!'\n",
    "    return document_path_similarity(doc1, doc2)\n",
    "test_document_path_similarity()\n",
    "# 0.554265873015873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "dc1b458a-1d5b-44a7-8aec-81c9ee33c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('ali.n.01'), Synset('saw.v.01'), Synset('man.n.01'), Synset('telescope.n.01')]\n",
      "[Synset('man.n.01'), Synset('telescope.n.01'), Synset('be.v.01'), Synset('see.v.01'), Synset('by.r.01'), Synset('ali.n.01')]\n",
      "0.7916666666666667\n",
      "0.5793650793650793\n",
      "0.685515873015873\n"
     ]
    }
   ],
   "source": [
    "doc1 = 'Ali saw the man with the telescope.'\n",
    "doc2 = 'The man with the telescope was seen by Ali.'\n",
    "synsets1 = doc_to_synsets(doc1)\n",
    "print(synsets1)\n",
    "synsets2 = doc_to_synsets(doc2)\n",
    "print(synsets2)\n",
    "score1 = similarity_score(synsets1, synsets2)\n",
    "print(score1)\n",
    "score2 = similarity_score(synsets2, synsets1)\n",
    "print(score2)\n",
    "score3 = document_path_similarity(doc1, doc2)\n",
    "print(score3)\n",
    "# [Synset('ali.n.01'), Synset('saw.v.01'), Synset('man.n.01'), Synset('telescope.n.01')]\n",
    "# [Synset('man.n.01'), Synset('telescope.n.01'), Synset('be.v.01'), Synset('see.v.01'), Synset('by.r.01'), Synset('ali.n.01')]\n",
    "# 0.7916666666666667\n",
    "# 0.6619047619047619\n",
    "# 0.7267857142857144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f1573dc6-a455-4e76-b2c3-262b3ff4d311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I', 'like', 'cats'],\n",
       " [('I', 'PRP'), ('like', 'VBP'), ('cats', 'NNS')],\n",
       " [None, 'v', 'n'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "304581b1-89d9-483b-912d-6e34051e2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_synsets(doc):  \n",
    "    text=word_tokenize(doc)\n",
    "    tags=pos_tag(text)\n",
    "    nw_tags=[convert_tag(i) for i in tags]\n",
    "    df=pd.DataFrame([tags,nw_tags]).transpose()\n",
    "    df.columns=['Tags','Nw_tags']\n",
    "    #     df=df[df['Nw_tags']!=None]\n",
    "    df=df.dropna()\n",
    "    df=df.reset_index()\n",
    "    syns=[]\n",
    "    for i in range(0,df.shape[0]):\n",
    "        try:\n",
    "            syns.append(wn.synsets(df.Tags[i][0],pos=df.Nw_tags[i])[0])\n",
    "        except:\n",
    "            continue\n",
    "    return syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "77ff2342-a835-4b18-b393-e0e1978f5dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('wish.v.02'), Synset('cat.n.01')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_synsets('I like cats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c7382a72-d409-4c61-bc71-7b2b16a7e9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " synsets1 = doc_to_synsets('I like cats')\n",
    "synsets2 = doc_to_synsets('I like dogs')\n",
    "similarity_score(synsets1, synsets2)\n",
    "# Out: 0.73333333333333339"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
